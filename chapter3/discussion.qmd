# Discussion {#sec-ch3-discussion}

In this part of the dissertation, we review LSTMs and evaluate their performance relative to our proposed MTD models. Through simulation studies, we compare both the Gamma MTD and ZIGamma MTD models against the LSTMs. For gamma time series, Gamma MTD and LSTM perform comparably, although further assessment using 10 replicates of Scenario 1 shows that MTD consistently outperforms LSTM. For zero-inflated gamma time series, ZIGamma MTD also outperforms the LSTM, which is expected given the challenges of modeling zero-inflated data, and LSTMs are less specialized for handling this type of data. 

In real-world data applications, we focus on comparing the Gamma MTD with LSTMs to assess their practical performance. In this case, Gamma MTD consistently outperforms the LSTM across all evaluation metrics for all three datasets, including wind speed measurements (m/s) at heights of 50 m, 10 m, and 2 m above ground level.

Although the MTD framework can, in principle, be extended to handle non-stationary time series and incorporate predictors incorporating additional model elements into the conditional mean structure [@zheng2022construction], these extensions have not yet been implemented. In addition, it is currently limited to a univariate setting. Consequently, it cannot effectively model non-stationary data, simultaneously capture the effects of past observations and relevant predictors, or account for multivariate dependence. Future research directions include extending the model to handle non-stationary features, account for variability in wind speed due to factors such as air density, and incorporate the dependence of wind speed across different heights. 

Probabilistic models like MTDs offer greater robustness and interpretability due to their probabilistic nature, allowing uncertainty quantification and insights into temporal dependence. Their robustness stem from their ability to capture complex patterns without overfitting, while their structure provides interpretable parameters. However, models such as Gamma MTD and ZIGamma MTD require careful design and specification. In contrast, deep learning networks such as LSTMs are more general-purpose and enable faster computation, though their black-box structure limits interpretability. Therefore, MTD is better suited for explainable and robust modeling, whereas LSTMs are advantageous for large-scale or computationally intensive tasks. 

With the growing adoption of transformer architectures, which leverage multi-head attention to model dependence in parallel, future research in sequence modeling should extend these comparisons to include transformer-based models. It is equally important that such comparisons are grounded in appropriate benchmarks and evaluated with suitable metrics to ensure fair and valid conclusions regarding model performance.

Building on the perspectives outlined by @wikle2023statistical, who reviewed traditional statistical and modern machine learning approaches for spatial and spatio-temporal data and highlighted the development of hybrid models for latent processes, data, and parameter specifications, a promising avenue for future research is the exploration of hybrid modeling strategies for time series data. Integrating classical probabilistic models with AI-driven architectures could combine the robustness and interpretability of probabilistic approaches with the flexibility and efficiency of neural networks, providing a rich framework for modeling complex features such as skewness, zero-inflation, and temporal dependence. 