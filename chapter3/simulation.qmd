# Simulation Studies {#sec-ch3-simu}

## Network Configuration

In this section, we provide an overview of network architecture, training process, hyperparameter tuning, and evaluation metrics for the LSTM network used in our study. 

Our design choices are informed by the findings of @hewamalage2021reviewrnn, which guide the appropriate settings for the LSTM network. The architecture consists of an input layer, followed by one to two LSTM layers, and concludes with a dense layer to balance model complexity and performance. 

The network is trained using Backpropagation Through Time (BPTT) [@mozer2013focused; @robinson1987utility; @werbos1988generalization]. Although the open-source Cocob (COntinuous COin Betting) optimizer is reported to perform the best, we use the built-in Adam optimizer for its practical convenience and competitive performance. The learning rate is initially set to $0.001$, consistent with recommended ranges for Adam. The batch size and cell dimension are initially set to $32$ and $64$, respectively, to balance training efficiency with model capacity, forming the foundation of our chosen configuration. In @sec-ch3-simu-res-gamma-expt3, we vary these hyperparameters to explore their impact on model performance, but find no improvement. Consequently, we reuse the original configuration for subsequent experiments, including the data application.

Finally, model performance is evaluated using RMSE, MAE, MAPE, SMAPE, and MASE, consistent with the metrics discussed in @sec-ch3-background. 

## Experimental Setup 

The goals of the simulation studies are threefold: (1) to compare the predictive performance of the LSTM and MTD models, both generally for gamma data and specifically for zero-inflated gamma data, (2) to assess the stability and robustness of their performance, and (3) to investigate the impact of hyperparameters on LSTM performance. 

To compare the predictive performance of the LSTM and MTD models under various conditions, we run both models on Gamma Scenario 1–9 (see @tbl-scenarios of Part I for details) and assess their performance using RMSE as the primary evaluation metric. Each model is trained and tested under identical data splits with a ratio of $0.8$ to ensure a fair comparison.

To assess the stability and robustness of model performance, we run both the LSTM and MTD models on 10 independently generated replicates of Gamma Scenario 1 (see @tbl-scenarios of Part I for details). Each replicate consists of a new synthetic dataset generated using the same underlying parameters but with different random seeds. This setup allows us to quantify the variability in model outcomes arising from randomness in data generation and model training, and to evaluate whether the observed performance differences between the LSTM and MTD models are statistically significant.

To investigate the impact of hyperparameters on LSTM performance, we run the network with a variety of configurations on Gamma Scenario 1 with 10 independently generated replicates for each configuration. The configurations explore key hyperparameters including the learning rate, the batch size, the number of layers, and the number of hidden units. Specifically, we evaluate the following LSTM configurations: 

1. Learning rate: $0.1$, $0.01$, and $0.001$

2. Batch size: $1$, $8$, $16$, $32$, $64$, and $128$

3. Number of layers: $1$, $2$, and $3$

4. Hidden cell dimensions: $32$, $64$, and $128$

This setup allows us to assess the sensitivity of LSTM performance to hyperparameter choices, identify optimial configurations that yield consistent and robust results, and inform the selection of settings for experiments conducted in @sec-ch3-real. 

For the zero-inflated Gamma settings, we focus exclusively on Scenario 1 (see @tbl-scenarios-zigamma of Part II for details), since each scenario includes six cases defined by all combinations of $P = 0.1, 0.5, 0.7,$ and $\epsilon = 0.1, 0.4$, where $P$ represents the zero-inflated probability and $\epsilon$ denotes the threshold value. We similarly run both models and evaluate their performance using RMSE, allowing us to specifically examine model behavior on zero-inflated data. Additionally, we compute RMSE **below** (i.e., RMSE for data less than or equal to $\epsilon$) and **above** (i.e., RMSE for data greater than $\epsilon$) to assess predictive accuracy in the lower and upper ranges, respectively. As discussed in @sec-ch2-pred, when $P$ is small, a large proportion of observations fall above $\epsilon$, providing more information to estimate the value in the upper range. As $P$ increases, more observations concentrate below $\epsilon$, making the RMSE in the near-zero range the primary indicator of the overall performance. These additional metrics provide insight into model performance for low and high-value regions, particularly relevant in the context of zero-inflated distributions. 

## Results {#sec-ch3-simu-res} 

### Prediction for Gamma Scenarios {#sec-ch3-simu-res-gamma}

#### Experiment 1: Model Performance Comparison For Gamma Scenarios

As discussed in @tbl-scenarios-description of Part I, Scenarios 1 and 2 follow the original MTD setup: Scenario 1 uses exponentially decreasing weights, which are typically observed in real-world data, and Scenario 2 uses unevenly arranged relevant lags. Scenarios 3 to 9 follow the same weight pattern as Scenario 1. Scenarios 3 to 6 evaluate gamma shape and rate, and Scenarios 7 to 9 consider high-skew cases. 

@tbl-pred-gamma-lstm-vs-mtd summarizes the RMSE comparisons between LSTM and MTD based on one-step ahead predicted means for Scenarios 1 through 9. The predicted results from LSTM and MTD are similar. RMSEs for MTD are lower in Scenarios 2, 3, 4, and 6, though the differences are minimal. Conversely, LSTM yields slightly lower RMSEs in Scenarios 7 to 9, though the differences are again minimal. RMSEs are the highest for both models in Scenario 2. @tbl-pred-gamma-lstm-vs-mtd-bias presents the corresponding bias comparisons across the same scenarios. Overall, biases are small, with positive values indicating overestimation and negative values underestimation.

@fig-lstm-vs-mtd-gamma-s12 illustrates these means for Scenario 1 and 2. @fig-lstm-vs-mtd-gamma-s12-zoom presents a zoomed-in view of the same plot, focusing on a subset of the test data ($n = 200$). As shown in Plot (a), both models predict well, with LSTM performing comparably to MTD. However, as shown in Plot (b), both models appear to struggle more in Scenario 2 compared to their performance in Scenario 1. Additional plots illustrating the predicted means for Scenarios 3 through 9 (@fig-lstm-vs-mtd-gamma-s3456, @fig-lstm-vs-mtd-gamma-s789) are provided in the @sec-appendix-ch3-add-pred @sec-appendix-ch3-add-pred-gamma. 

```{=latex}
\begin{table}[ht]
\centering
\caption{RMSE Comparison of LSTM and MTD for Gamma Scenarios 1–9 (s1–s9).}
\label{tbl-pred-gamma-lstm-vs-mtd}
\tagpdfsetup{table/header-rows={1}}
\begin{tabular}{lrrr}
  \hline
. & LSTM & MTD \\ 
  \hline
s1 & \textbf{1.3326} & 1.3569 \\ 
  s2 & 2.3001 & \textbf{2.1988} \\ 
  s3 & 1.0700 & \textbf{1.0446} \\ 
  s4 & 1.6846 & \textbf{1.5282} \\ 
  s5 & \textbf{1.0215} & 1.1296 \\ 
  s6 & 0.8263 & \textbf{0.7649} \\ 
  s7 & \textbf{0.7452} & 0.7617 \\ 
  s8 & \textbf{0.3675} & 0.3808 \\ 
  s9 & \textbf{0.1837} & 0.1902 \\ 
   \hline
\end{tabular}
\end{table}
```

```{=latex}
\begin{table}[ht]
\centering
\caption{Bias Comparison of LSTM and MTD for Gamma Scenarios 1–9 (s1–s9).}
\label{tbl-pred-gamma-lstm-vs-mtd-bias}
\tagpdfsetup{table/header-rows={1}}
\begin{tabular}{lrr}
  \hline
. & LSTM & MTD \\ 
  \hline
s1 & \textbf{0.0347} & 0.0749 \\ 
  s2 & 0.2533 & \textbf{0.1611} \\ 
  s3 & 0.1487 & \textbf{0.0614} \\ 
  s4 & \textbf{-0.0691} & 0.0836 \\ 
  s5 & 0.0733 & \textbf{0.0684} \\ 
  s6 & 0.1508 & \textbf{0.0422} \\ 
  s7 & 0.2311 & \textbf{0.0467} \\ 
  s8 & \textbf{0.0224} & 0.0233 \\ 
  s9 & 0.0289 & \textbf{0.0117} \\ 
   \hline
\end{tabular}
\end{table}
```

![One-step-ahead predicted means for (a) Gamma Scenario 1 and (b) Scenario 2: Solid (black) lines are true values. Dashed (red) lines are LSTM predicted means and dashed (blue) lines are MTD predicted means.](../images/chapter3/lstm_vs_mtd_gamma_s12_rmse.png){#fig-lstm-vs-mtd-gamma-s12 fig-alt="Predicted means for two gamma scenarios"} 

![Zoomed-in view of one-step ahead predicted means for (a) Gamma Scenario 1 and (b) Scenario 2: Solid (black) lines are true values. Dashed (red) lines are LSTM predicted means and dashed (blue) lines are MTD predicted means.](../images/chapter3/lstm_vs_mtd_gamma_s12_rmse_n200.png){#fig-lstm-vs-mtd-gamma-s12-zoom fig-alt="Predicted means for two gamma scenarios with a zoomed-in view"} 

#### Experiment 2: Stability and Robustness Analysis

Using Scenario 1 with 10 replicates, we conduct additional analyses to evaluate model performance and assess whether the performance differences between LSTM and MTD are significant. Results from the paired t-test indicated a mean difference in RMSE of $0.1290$ ($\text{p-value} = 0.005175$, $\text{df} = 9$), with MTD consistently yielding lower RMSEs. @fig-table-lstm-mtd illustrates these findings. 

![Relative Performance of LSTM and MTD models for Gamma Scenario 1 (Mean RMSE for LSTM = 1.5290; Mean RMSE for MTD = 1.4000). Data points are connected by lines to indicate results from the same replicate.](../images/chapter3/lstm_vs_mtd_table_2.png){#fig-table-lstm-mtd width=50% fig-alt="RMSE results using 10 replicates"}

#### Experiment 3: Impact of Hyperparameters on LSTM Performance {#sec-ch3-simu-res-gamma-expt3}

Reusing Scenario 1 with 10 replicates, we perform additional analyses to determine whether hyperparameter tuning is necessary. For each hyperparameter, we conduct a repeated-measures ANOVA, treating hyperparameter levels as the treatment factor and replicate ID, representing different simulated data replicates, as the random effect. If the overall p-value is smaller than $0.05$, we follow up with the Bonferroni-corrected pairwise comparisons to identify which pairs differ significantly. 

Among these configurations, the p-value is statistically significant for batch size ($\text{Pr}(>\text{F}) = 4.4\text{e}-06$, $\text{df} = 2, 24$), and pairwise comparisons indicate that RMSEs differ significantly only between batch size $64$ and all other batch sizes ($1, 8, 16, 32,$ and $128$), as well as between batch size 128 and all other batch sizes ($1, 8, 16, 32,$ and $64$). The p-value is also significant for cell dimensions ($\text{Pr}(>\text{F}) = 0.0113$, $\text{df} = 2, 24$); however, pairwise comparisons reveal significant differences in RMSE only between cell dimensions of $32$ and $64$, as well as between $32$ and $128$, but not between $64$ and $128$. @fig-table-lstm illustrates these findings. 

These results indicate that further hyperparameter tuning yields minimal performance gains. Notably, reducing the batch size slows down model training, although the model still completes within minutes, but does not produce a practical improvement in RMSE. Therefore, we adopt the default configuration for subsequent experiments: learning rate = $0.001$, batch size = $32$, number of layers = $1$, and cell dimension = $64$. 

![Relative performance of LSTM networks with varying learning rates (0.1, 0.01, 0.001), batch sizes (1, 8, 16, 32, 64, 128), number of layers (1–3), and cell dimensions (32, 64, 128) for Gamma Scenario 1.](../images/chapter3/lstm_table_2.png){#fig-table-lstm fig-alt="RMSE results using 10 replicates with varying hyperparameter configurations"}

### Prediction for Zero-inflated Gamma Scenarios {#sec-ch3-simu-res-zigamma}

#### Experiment 4: Model Performance Comparison For Zero-inflated Gamma Scenarios

@tbl-pred-zigamma-lstm-vs-mtd summarizes the RMSE comparisons between LSTM and MTD based on one-step ahead predicted means for Scenario 1, with rows correspond to all combinations of $Pi = 0.1, 0.5, 0.7,$ and $\epsilon = 0.1, 0.4$, where $P$ is the zero-inflated probability and $\epsilon$ is the threshold value. LSTM generally achieves lower overall RMSEs compared to MTD. 

However, patterns similar to those in @sec-ch2-pred of Part II reappear. The overall RMSE can obscure important differences in predictive performance. To provide a clearer picture, we decompose the RMSE into **below** (which captures accuracy on values less than or equal to $\epsilon$) and **above** (which reflects predictive accuracy for values exceeding $\epsilon$) in @tbl-pred-zigamma-lstm-vs-mtd-lu. Specifically, for zero-inflated gamma data with low zero-inflation probability (e.g., $P = 0.1$), the RMSE **above** is a more informative measure of performance. As $P$ increases, this relationship reverses, and the RMSE **below** becomes more relevant. As shown in @tbl-pred-zigamma-lstm-vs-mtd-lu, when $P = 0.1$, MTD outperforms LSTM in RMSE **above**. This trend persists at higher levels of zero-inflation (e.g., $P = 0.5$, $0.7$), where MTD again yields lower values for RMSE **below** than LSTM. @tbl-pred-zigamma-lstm-vs-mtd-bias presents the corresponding bias comparisons across the same scenario. Similar pattern emerges.

@fig-lstm-vs-mtd-zigamma-s1 illustrates these patterns for Scenario 1. @fig-lstm-vs-mtd-zigamma-s1-zoom presents a zoomed-in view of the same plot, focusing on a subset of the test data ($n = 200$). Results for Scenario 2 (@tbl-pred-zigamma-lstm-vs-mtd-s2, @tbl-pred-zigamma-lstm-vs-mtd-s2-lu, @tbl-pred-zigamma-lstm-vs-mtd-s2-bias, @tbl-pred-zigamma-lstm-vs-mtd-s2-lu-bias, @fig-lstm-vs-mtd-zigamma-s2, @fig-lstm-vs-mtd-zigamma-s2-zoom) are provided in @sec-appendix-ch3-add-pred @sec-appendix-ch3-add-pred-zigamma and are similar to those in Scenario 1. 

```{=latex}
\begin{table}[ht]
\centering
\caption{RMSE Comparison of LSTM and MTD for ZIGamma Scenarios 1. Each row label indicates the combination of $P$ (zero-inflated probability) and $\epsilon$ (threshold value) used in the simulation.}
\label{tbl-pred-zigamma-lstm-vs-mtd}
\tagpdfsetup{table/header-rows={1}}
\begin{tabular}{lrr}
  \hline
. & LSTM & MTD \\ 
  \hline
P01Eps01 & \textbf{1.7221} & 1.7302 \\ 
  P01Eps04 & \textbf{2.0843} & 2.6386 \\ 
  P05Eps01 & \textbf{2.1102} & 2.8361 \\ 
  P05Eps04 & \textbf{2.1788} & 2.1922 \\ 
  P07Eps01 & \textbf{2.2762} & 3.0739 \\ 
  P07Eps04 & \textbf{2.0916} & 2.5798 \\ 
   \hline
\end{tabular}
\end{table}
```

```{=latex}
\begin{table}[ht]
\centering
\caption{RMSE Comparison of LSTM and MTD for ZIGamma Scenarios 1 Above and Below. Each row label indicates the combination of $P$ (zero-inflated probability) and $\epsilon$ (threshold value) used in the simulation. Reported values show decomposed RMSE below and above the threshold.}
\label{tbl-pred-zigamma-lstm-vs-mtd-lu}
\tagpdfsetup{table/header-rows={1}}
\begin{tabular}{lrrrr}
  \hline
. & LSTM Below & MTD Below & LSTM Above & MTD Above \\ 
  \hline
P01Eps01 & 3.6285 & 4.2964 & 1.4910 & \textbf{1.3668} \\ 
  P01Eps04 & 3.2122 & 5.9082 & 1.8826 & \textbf{1.7945} \\ 
  P05Eps01 & 2.0551 & \textbf{0.7752} & 2.1655 & 3.9641 \\ 
  P05Eps04 & 2.0495 & \textbf{1.6675} & 2.3426 & 2.7477 \\ 
  P07Eps01 & 1.2984 & \textbf{0.3677} & 3.5798 & 5.4580 \\ 
  P07Eps04 & 1.2583 & \textbf{0.5346} & 3.3044 & 4.6465 \\ 
   \hline
\end{tabular}
\end{table}
```

```{=latex}
\begin{table}[ht]
\centering
\caption{Bias Comparison of LSTM and MTD for ZIGamma Scenarios 1. Each row label indicates the combination of $P$ (zero-inflated probability) and $\epsilon$ (threshold value) used in the simulation.}
\label{tbl-pred-zigamma-lstm-vs-mtd-bias}
\tagpdfsetup{table/header-rows={1}}
\begin{tabular}{lrr}
  \hline
. & LSTM & MTD \\ 
  \hline
P01Eps01 & \textbf{-0.0958} & 0.1713 \\ 
  P01Eps04 & \textbf{-0.4361} & 1.2466 \\ 
  P05Eps01 & \textbf{0.1945} & -1.5305 \\ 
  P05Eps04 & 0.3950 & \textbf{-0.1121} \\ 
  P07Eps01 & \textbf{-0.1006} & -1.4796 \\ 
  P07Eps04 & \textbf{0.0023} & -0.9728 \\ 
   \hline
\end{tabular}
\end{table}
```

```{=latex}
\begin{table}[ht]
\centering
\caption{Bias Comparison of LSTM and MTD for ZIGamma Scenarios 1 Above and Below. Each row label indicates the combination of $P$ (zero-inflated probability) and $\epsilon$ (threshold value) used in the simulation. Reported values show overall RMSE, with decomposed RMSE below and above the threshold.}
\label{tbl-pred-zigamma-lstm-vs-mtd-lu-bias}
\tagpdfsetup{table/header-rows={1}}
\begin{tabular}{lrrrr}
  \hline
. & LSTM Below & MTD Below & LSTM Above & MTD Above \\ 
  \hline
P01Eps01 & 3.6105 & 4.2598 & -0.3655 & \textbf{-0.1262} \\ 
  P01Eps04 & 3.1820 & 5.8832 & -0.9206 & \textbf{0.6257} \\ 
  P05Eps01 & 2.0234 & \textbf{0.6896} & -1.6904 & -3.8186 \\ 
  P05Eps04 & 2.0416 & \textbf{1.5973} & -1.8362 & -2.4284 \\ 
  P07Eps01 & 1.2785 & \textbf{0.2471} & -3.1124 & -5.2506 \\ 
  P07Eps04 & 1.2235 & \textbf{0.4784} & -2.8609 & -4.3752 \\ 
   \hline
\end{tabular}
\end{table}
```

![One-step ahead predicted means for ZIGamma Scenario 1: Solid (black) lines are true values. Dashed (red) lines are LSTM predicted means and dashed (blue) lines are MTD predicted means. Reported values show overall RMSE, with decomposed RMSE below and above the threshold shown in parentheses: RMSE (RMSE for data $\leq \epsilon$, RMSE for data $> \epsilon$).](../images/chapter3/lstm_vs_mtd_zigamma_s1_rmse.png){#fig-lstm-vs-mtd-zigamma-s1 fig-alt="Predicted means for zero-inflated gamma scenario 1"} 

![Zoomed-in view of one-step ahead predicted means for ZIGamma Scenario 1: Solid (black) lines are true values. Dashed (red) lines are LSTM predicted means and dashed (blue) lines are MTD predicted means. Reported values show overall RMSE, with decomposed RMSE below and above the threshold shown in parentheses: RMSE (RMSE for data $\leq \epsilon$, RMSE for data $> \epsilon$).](../images/chapter3/lstm_vs_mtd_zigamma_s1_rmse_n200.png){#fig-lstm-vs-mtd-zigamma-s1-zoom fig-alt="Predicted means for zero-inflated gamma scenario 1 with a zoomed-in view"}

